# -*- coding: utf-8 -*-
"""assessment2.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zb3c-G3BBYzPA38svo8EzVkjK0aMxbi5
"""

import numpy as np
import pandas as pd

pip install matplotlib

import matplotlib.pyplot as plt
import seaborn as sns

sample=pd.read_csv('/content/sample_submission_M0L0uXE.csv')

sample.head()

train=pd.read_csv('/content/train_LZdllcl.csv')

train.head()

train.info()

train.shape

train=pd.get_dummies(train,dtype=int)

train.head()

train.isna().sum()

plt.hist(train['previous_year_rating'])
plt.show()

train['previous_year_rating']=train['previous_year_rating'].fillna(train['previous_year_rating'].median())

train['previous_year_rating'].isna().sum()

test=pd.read_csv('/content/test_2umaH9m.csv')

test.head()

test.shape

test.info()

test.columns

test.isna().sum()

test['previous_year_rating']=test['previous_year_rating'].fillna(test['previous_year_rating'].median())

test['education']=test['education'].fillna(test['education'].mode()[0])

test[['previous_year_rating','education']].isna().sum()

test=pd.get_dummies(test,dtype=int)

x_train=train.drop('is_promoted',axis=1)
y_train=train['is_promoted']

from sklearn.svm import SVC
sv_cls=SVC(kernel='rbf')
sv_cls=sv_cls.fit(x_train,y_train)

y_pred_svm=sv_cls.predict(test)

y_test=sample['is_promoted']

from sklearn.metrics import confusion_matrix,accuracy_score,precision_score

accuracy_score(y_test,y_pred_svm)

precision_score(y_test,y_pred_svm,average='micro')

from sklearn.tree import DecisionTreeClassifier

dt1_cls=DecisionTreeClassifier()
dt1_cls=dt1_cls.fit(x_train,y_train)
y_pred_dt1=dt1_cls.predict(test)

accuracy_score(y_test,y_pred_dt1)

precision_score(y_test,y_pred_dt1,average='micro')

y_pred_dt1

y_predict1=pd.DataFrame(y_pred_dt1)

y_predict1.tail(3490)

from sklearn.ensemble import RandomForestClassifier
rd1_cls= RandomForestClassifier()
rd1_cls=rd1_cls.fit(x_train,y_train)
y_pred_rd1=rd1_cls.predict(test)

accuracy_score(y_test,y_pred_rd1)

precision_score(y_test,y_pred_rd1,average='micro')

y_predictr=pd.DataFrame(y_pred_dt1)

y_predictr.tail(3490)

from sklearn.linear_model import LogisticRegression
log_reg= LogisticRegression()
log_reg=log_reg.fit(x_train,y_train)

y_pred=log_reg.predict(test)

accuracy_score(y_test,y_pred)

precision_score(y_test,y_pred,average='micro')

y_predlog=pd.DataFrame(y_pred)

y_predlog.tail(3490)

from sklearn.neighbors import KNeighborsClassifier
metric_k=[]
neighbors=np.arange(3,15)

for k in neighbors:
  classifier=KNeighborsClassifier(n_neighbors=k,metric='euclidean')
  classifier.fit(x_train,y_train)
  y_predictions=classifier.predict(test)
  acc=accuracy_score(y_test,y_predictions)
  metric_k.append(acc)

metric_k

plt.plot(neighbors,metric_k,'-o',color='green')
plt.xlabel('K-Value')
plt.ylabel('Accuracy')
plt.grid()

classifier=KNeighborsClassifier(n_neighbors=14,metric='euclidean')
classifier.fit(x_train,y_train)
y_predictions=classifier.predict(test)

accuracy_score(y_test,y_predictions)

precision_score(y_test,y_predictions,average='micro')

from sklearn.naive_bayes import GaussianNB
nbClassifier= GaussianNB()
nbClassifier.fit(x_train,y_train)

ypred=nbClassifier.predict(test)

accuracy_score(y_test,ypred)

precision_score(y_test,ypred,average='micro')

